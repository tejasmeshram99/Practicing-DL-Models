{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwum4SrOc+OO33UWCU0zT+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejasmeshram99/Practicing-DL-Models/blob/master/GANs/InfoGAN/InfoGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IpJ5cw2diV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import itertools\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "641y14KNjog3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(74,1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(1024,128*7*7),\n",
        "        nn.BatchNorm1d(128*7*7),\n",
        "        nn.ReLU(True),\n",
        "    )\n",
        "\n",
        "    self.gen = nn.Sequential(\n",
        "        nn.ConvTranspose2d(128,64,4,2,1,bias = False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(64,1,4,2,1,bias = False),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc(x)\n",
        "    x = x.view(-1,128,7,7)\n",
        "    x = self.gen(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmbSVQDFAuGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FrontEnd(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Conv2d(1,64,4,2,1),\n",
        "        nn.LeakyReLU(0.1,inplace = True),\n",
        "        nn.Conv2d(64,128,4,2,1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.1,inplace = True),\n",
        "    )  \n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.layer(x)\n",
        "    x = x.view(-1,128*7*7)\n",
        "\n",
        "    return x  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkRsm62Spmda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.prob = nn.Sequential(     \n",
        "        nn.Linear(128*7*7,1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Linear(1024,512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Linear(512,128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Linear(128,1),\n",
        "        \n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.prob(x)\n",
        "    x = F.sigmoid(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlxn3GrfKV3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recognizer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.classprob = nn.Sequential(     \n",
        "        nn.Linear(128*7*7,1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Linear(1024,512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Linear(512,128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Linear(128,10),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.classprob(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OS8KR4KeQHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
        "train_images = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_images, batch_size=100,shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dlNlLE5fPMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv')!=-1:\n",
        "    m.weight.data.normal_(0.0,0.02)\n",
        "  elif classname.find('BatchNorm')!=-1:\n",
        "    m.weight.data.normal_(1.0, 0.02)\n",
        "    m.bias.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swOjpfLiPAvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_noise(batch_size):\n",
        "  idx = np.random.randint(10,size = batch_size)\n",
        "  c = np.zeros((batch_size,10))\n",
        "  c[range(batch_size),idx] = 1\n",
        "  c = torch.Tensor(c)\n",
        "  noise = torch.FloatTensor(batch_size,64)\n",
        "  noise.data.uniform_(-10,10)\n",
        "  z = torch.cat((noise,c),1).view(-1,74)\n",
        "  z = z.cuda()\n",
        "\n",
        "  return z, idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAo4irRNZFUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a495e31f-16b8-4fd8-8c96-55d03f15f433"
      },
      "source": [
        "G = Generator().cuda()\n",
        "FE = FrontEnd().cuda()\n",
        "D = Discriminator().cuda()\n",
        "Q = Recognizer().cuda()\n",
        "\n",
        "G.apply(weights_init)\n",
        "FE.apply(weights_init)\n",
        "D.apply(weights_init)\n",
        "Q.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Recognizer(\n",
              "  (classprob): Sequential(\n",
              "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
              "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (6): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2oQ7cOfZvMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion_D_FE = nn.BCELoss()\n",
        "criterion_GQ = nn.CrossEntropyLoss()\n",
        "optimizer_D_FE = optim.Adam([{'params':FE.parameters()}, {'params':D.parameters()}], lr=0.0002, betas=(0.5, 0.99))\n",
        "optimizer_GQ = optim.Adam([{'params':G.parameters()}, {'params':Q.parameters()}], lr=0.001, betas=(0.5, 0.99))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CziUZiQC-R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_test_samples = 100\n",
        "num_epochs = 15\n",
        "index = np.arange(10).repeat(10)\n",
        "one_hot = np.zeros((num_test_samples,10))\n",
        "one_hot[range(num_test_samples), index] = 1\n",
        "test_noise = torch.FloatTensor(num_test_samples,64)\n",
        "test_noise.data.uniform_(-10,10)\n",
        "test_z = torch.cat((test_noise,torch.Tensor(one_hot)),1).view(-1,74)\n",
        "test_z = test_z.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5VScZeYJHTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7d565ce-efdf-430f-e53a-b7e8706089b0"
      },
      "source": [
        "# Training\n",
        "for epoch in range(num_epochs):\n",
        "  for n,(images,_) in enumerate(train_loader):\n",
        "    bs = images.size(0)   #batch size\n",
        "    images = Variable(images).cuda()\n",
        "\n",
        "    optimizer_D_FE.zero_grad()\n",
        "    target1 = torch.Tensor(np.ones(bs)).cuda()\n",
        "    target1 = Variable(target1,requires_grad = False)\n",
        "    out = FE(images)\n",
        "    real_prob = D(out)\n",
        "    real_loss = criterion_D_FE(real_prob,target1)\n",
        "    real_loss.backward()\n",
        "\n",
        "    z,idx = gen_noise(bs)\n",
        "    z = Variable(z)\n",
        "    target2 = torch.Tensor(np.zeros(bs)).cuda()\n",
        "    target2 = Variable(target2,requires_grad = False)\n",
        "    fake_image = G(z)\n",
        "    feout_G = FE(fake_image)\n",
        "    fake_prob = D(feout_G)\n",
        "    fake_loss = criterion_D_FE(fake_prob,target2)\n",
        "    fake_loss.backward(retain_graph = True)\n",
        "\n",
        "    D_loss = real_loss + fake_loss\n",
        "    optimizer_D_FE.step()\n",
        "\n",
        "    \n",
        "    optimizer_GQ.zero_grad()\n",
        "    feout_G = FE(fake_image)\n",
        "    fake_prob = D(feout_G)\n",
        "    label = torch.Tensor(np.ones(bs))\n",
        "    label = label.cuda()\n",
        "    label = Variable(label,requires_grad=False)\n",
        "    reconstruct_loss = criterion_D_FE(fake_prob,label)\n",
        "\n",
        "    q_logits = Q(feout_G)\n",
        "    target3 = torch.LongTensor(idx).cuda()\n",
        "    target3 = Variable(target3)\n",
        "    q_loss = criterion_GQ(q_logits,target3)\n",
        "    G_loss = reconstruct_loss + q_loss\n",
        "    G_loss.backward(retain_graph = True)\n",
        "    optimizer_GQ.step()\n",
        "\n",
        "    if n % 100 == 0:\n",
        "      print('Epoch/Iter:{0}/{1}, Dloss: {2}, Gloss: {3}'.format(\n",
        "      epoch, n, D_loss.data.cpu().numpy(),G_loss.data.cpu().numpy())    \n",
        "          )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch/Iter:0/0, Dloss: 1.4241058826446533, Gloss: 3.062471628189087\n",
            "Epoch/Iter:0/100, Dloss: 1.4273419380187988, Gloss: 3.118267774581909\n",
            "Epoch/Iter:0/200, Dloss: 1.4225895404815674, Gloss: 3.0024032592773438\n",
            "Epoch/Iter:0/300, Dloss: 1.4163697957992554, Gloss: 3.070539712905884\n",
            "Epoch/Iter:0/400, Dloss: 1.422751545906067, Gloss: 3.08467960357666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch/Iter:1/0, Dloss: 1.4215741157531738, Gloss: 3.035616636276245\n",
            "Epoch/Iter:1/100, Dloss: 1.4263967275619507, Gloss: 3.0620474815368652\n",
            "Epoch/Iter:1/200, Dloss: 1.4309176206588745, Gloss: 3.0539472103118896\n",
            "Epoch/Iter:1/300, Dloss: 1.4317901134490967, Gloss: 3.1278605461120605\n",
            "Epoch/Iter:1/400, Dloss: 1.425169587135315, Gloss: 3.097337484359741\n",
            "Epoch/Iter:2/0, Dloss: 1.4198166131973267, Gloss: 3.0535776615142822\n",
            "Epoch/Iter:2/100, Dloss: 1.4231886863708496, Gloss: 3.0554373264312744\n",
            "Epoch/Iter:2/200, Dloss: 1.4218871593475342, Gloss: 3.1453962326049805\n",
            "Epoch/Iter:2/300, Dloss: 1.424310326576233, Gloss: 3.0779623985290527\n",
            "Epoch/Iter:2/400, Dloss: 1.4170933961868286, Gloss: 3.1190378665924072\n",
            "Epoch/Iter:3/0, Dloss: 1.4311838150024414, Gloss: 3.1377978324890137\n",
            "Epoch/Iter:3/100, Dloss: 1.4316771030426025, Gloss: 3.076446533203125\n",
            "Epoch/Iter:3/200, Dloss: 1.4228405952453613, Gloss: 3.0053305625915527\n",
            "Epoch/Iter:3/300, Dloss: 1.4267805814743042, Gloss: 3.085775375366211\n",
            "Epoch/Iter:3/400, Dloss: 1.4188597202301025, Gloss: 3.0503995418548584\n",
            "Epoch/Iter:4/0, Dloss: 1.4194129705429077, Gloss: 3.071272134780884\n",
            "Epoch/Iter:4/100, Dloss: 1.4262495040893555, Gloss: 3.035546064376831\n",
            "Epoch/Iter:4/200, Dloss: 1.4258896112442017, Gloss: 3.106471061706543\n",
            "Epoch/Iter:4/300, Dloss: 1.4183259010314941, Gloss: 3.1330580711364746\n",
            "Epoch/Iter:4/400, Dloss: 1.423101782798767, Gloss: 3.009760618209839\n",
            "Epoch/Iter:5/0, Dloss: 1.4186339378356934, Gloss: 3.085733652114868\n",
            "Epoch/Iter:5/100, Dloss: 1.425501823425293, Gloss: 3.103339195251465\n",
            "Epoch/Iter:5/200, Dloss: 1.4165260791778564, Gloss: 3.0858044624328613\n",
            "Epoch/Iter:5/300, Dloss: 1.4250380992889404, Gloss: 3.114494562149048\n",
            "Epoch/Iter:5/400, Dloss: 1.424829363822937, Gloss: 3.0728108882904053\n",
            "Epoch/Iter:6/0, Dloss: 1.420905351638794, Gloss: 3.0203497409820557\n",
            "Epoch/Iter:6/100, Dloss: 1.4236942529678345, Gloss: 3.0532424449920654\n",
            "Epoch/Iter:6/200, Dloss: 1.4283372163772583, Gloss: 3.0259499549865723\n",
            "Epoch/Iter:6/300, Dloss: 1.4276905059814453, Gloss: 3.0718350410461426\n",
            "Epoch/Iter:6/400, Dloss: 1.422417163848877, Gloss: 3.0841708183288574\n",
            "Epoch/Iter:7/0, Dloss: 1.4211481809616089, Gloss: 3.0174715518951416\n",
            "Epoch/Iter:7/100, Dloss: 1.4254792928695679, Gloss: 3.0999088287353516\n",
            "Epoch/Iter:7/200, Dloss: 1.4211266040802002, Gloss: 3.1748147010803223\n",
            "Epoch/Iter:7/300, Dloss: 1.4241583347320557, Gloss: 3.027580738067627\n",
            "Epoch/Iter:7/400, Dloss: 1.4174576997756958, Gloss: 3.0669729709625244\n",
            "Epoch/Iter:8/0, Dloss: 1.4222164154052734, Gloss: 3.0802698135375977\n",
            "Epoch/Iter:8/100, Dloss: 1.421438455581665, Gloss: 3.041712999343872\n",
            "Epoch/Iter:8/200, Dloss: 1.4258942604064941, Gloss: 3.1274218559265137\n",
            "Epoch/Iter:8/300, Dloss: 1.4293372631072998, Gloss: 3.0884244441986084\n",
            "Epoch/Iter:8/400, Dloss: 1.4227088689804077, Gloss: 3.048370361328125\n",
            "Epoch/Iter:9/0, Dloss: 1.4280481338500977, Gloss: 3.0716700553894043\n",
            "Epoch/Iter:9/100, Dloss: 1.4275338649749756, Gloss: 3.097449779510498\n",
            "Epoch/Iter:9/200, Dloss: 1.4253997802734375, Gloss: 3.0463080406188965\n",
            "Epoch/Iter:9/300, Dloss: 1.4228945970535278, Gloss: 3.074450969696045\n",
            "Epoch/Iter:9/400, Dloss: 1.4259175062179565, Gloss: 3.064764976501465\n",
            "Epoch/Iter:10/0, Dloss: 1.4209942817687988, Gloss: 3.071155071258545\n",
            "Epoch/Iter:10/100, Dloss: 1.4245156049728394, Gloss: 3.0487804412841797\n",
            "Epoch/Iter:10/200, Dloss: 1.4295530319213867, Gloss: 3.0711491107940674\n",
            "Epoch/Iter:10/300, Dloss: 1.4260083436965942, Gloss: 3.0432605743408203\n",
            "Epoch/Iter:10/400, Dloss: 1.4211506843566895, Gloss: 3.080679178237915\n",
            "Epoch/Iter:11/0, Dloss: 1.4265105724334717, Gloss: 3.13558030128479\n",
            "Epoch/Iter:11/100, Dloss: 1.4215307235717773, Gloss: 3.163271427154541\n",
            "Epoch/Iter:11/200, Dloss: 1.431282639503479, Gloss: 3.0561766624450684\n",
            "Epoch/Iter:11/300, Dloss: 1.4351303577423096, Gloss: 3.0703744888305664\n",
            "Epoch/Iter:11/400, Dloss: 1.4136875867843628, Gloss: 3.0902490615844727\n",
            "Epoch/Iter:12/0, Dloss: 1.421356201171875, Gloss: 3.127795696258545\n",
            "Epoch/Iter:12/100, Dloss: 1.4178907871246338, Gloss: 3.1235461235046387\n",
            "Epoch/Iter:12/200, Dloss: 1.42154860496521, Gloss: 3.0644290447235107\n",
            "Epoch/Iter:12/300, Dloss: 1.428138256072998, Gloss: 3.1043553352355957\n",
            "Epoch/Iter:12/400, Dloss: 1.4253532886505127, Gloss: 2.9964001178741455\n",
            "Epoch/Iter:13/0, Dloss: 1.4281103610992432, Gloss: 3.126966714859009\n",
            "Epoch/Iter:13/100, Dloss: 1.4190715551376343, Gloss: 3.0855190753936768\n",
            "Epoch/Iter:13/200, Dloss: 1.4257776737213135, Gloss: 3.0607099533081055\n",
            "Epoch/Iter:13/300, Dloss: 1.420466423034668, Gloss: 3.130862236022949\n",
            "Epoch/Iter:13/400, Dloss: 1.4200201034545898, Gloss: 3.1255111694335938\n",
            "Epoch/Iter:14/0, Dloss: 1.4218776226043701, Gloss: 3.092900276184082\n",
            "Epoch/Iter:14/100, Dloss: 1.428497314453125, Gloss: 3.078892230987549\n",
            "Epoch/Iter:14/200, Dloss: 1.420803427696228, Gloss: 3.1224513053894043\n",
            "Epoch/Iter:14/300, Dloss: 1.4164642095565796, Gloss: 3.0356297492980957\n",
            "Epoch/Iter:14/400, Dloss: 1.427472710609436, Gloss: 3.1164848804473877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZDuy-JK_ifM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = G(test_z)\n",
        "save_image(test_images.data,'./data/epoch_{:d}_pytorch.png'.format(epoch),nrow=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB2uqAQ9Xy9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}